}
# parameters
set.seed(100)
d_vec = seq(0,4)
# generate data
train.df = genData(n=200,seed=100)
test.df = genData(400)
# create k-fold indexes
k=5
inds.part = myCVids(n=nrow(train.df),K=k)
# create a data frame to save results into
M = matrix(0, nrow = (length(d_vec)), ncol = k+1)
KFOLD_df = data.frame(M)
KFOLD_df[,1] = d_vec # add degrees to results table
colnames(KFOLD_df) = c("Degree", seq(k))
# loop over k-folds
for( k in seq(k)){
isk = (inds.part == k) # k varies from 1 to K
valid.k = which(isk) # test data index
train.k = which(!isk)
# split data
train_sub_df = train.df[train.k,]
valid_df = train.df[valid.k,]
d_mse_vec = c()
for(d in d_vec){
if(d==0){
# train a polynomial model
PR = lm(y ~ 1, data=train_sub_df)
}else{
# train a polynomial model
PR = lm(y ~ poly(x, d, raw = TRUE), data=train_sub_df)
}
# get predicted values to calculate MSE
pred_val = predict(PR, valid_df, type="response")
pred_true_val_df = data.frame(pred = pred_val, actual = valid_df$y)
#calculate MSE
mse = mean((pred_true_val_df$actual - pred_true_val_df$pred)^2)
d_mse_vec = c(d_mse_vec, mse)
}
KFOLD_df[,k+1] = d_mse_vec
}
# tally of MSE
KFOLD_df$Total_MSE = rowSums(KFOLD_df[2:ncol(KFOLD_df)])
knitr::kable(KFOLD_df,
format = "markdown",
caption = "MSE by 5 folds at different degrees on validation data.") # display table
# print best d value
print(paste("The best K-fold degree is: ",
as.character(KFOLD_df[which.min(KFOLD_df$Total_MSE),]$Degree)))
# create k-fold indexes
k=nrow(train.df)
inds.part = myCVids(n=nrow(train.df),K=k)
# create a data frame to save results into
M = matrix(0, nrow = (length(d_vec)), ncol = k+1)
LOOCV_df = data.frame(M)
LOOCV_df[,1] = d_vec # add degrees to results table
colnames(LOOCV_df) = c("Degree", seq(k))
# loop over k-folds
for( k in seq(k)){
isk = (inds.part == k) # k varies from 1 to K
valid.k = which(isk) # test data index
train.k = which(!isk)
# split data
train_sub_df = train.df[train.k,]
valid_df = train.df[valid.k,]
d_mse_vec = c()
for(d in d_vec){
if(d==0){
# train a polynomial model
PR = lm(y ~ 1, data=train_sub_df)
}else{
# train a polynomial model
PR = lm(y ~ poly(x, d, raw = TRUE), data=train_sub_df)
}
# get predicted values to calculate MSE
pred_val = predict(PR, valid_df, type="response")
pred_true_val_df = data.frame(pred = pred_val, actual = valid_df$y)
#calculate MSE
mse = mean((pred_true_val_df$actual - pred_true_val_df$pred)^2)
d_mse_vec = c(d_mse_vec, mse)
}
LOOCV_df[,k+1] = d_mse_vec
}
# estimate test data MSE
test_d_vec = c()
for(d in d_vec){
if(d==0){
# train a polynomial model
PR = lm(y ~ 1, data=train.df)
}else{
# train a polynomial model
PR = lm(y ~ poly(x, d, raw = TRUE), data=train.df)
}
# get predicted values to calculate MSE
pred_val = predict(PR, test.df, type="response")
pred_true_val_df = data.frame(pred = pred_val, actual = test.df$y)
#calculate MSE
mse = mean((pred_true_val_df$actual - pred_true_val_df$pred)^2)
test_d_vec = c(test_d_vec, mse)
}
# tally of MSE
LOOCV_df$Total_validation_MSE = rowSums(LOOCV_df[2:ncol(LOOCV_df)])
LOOCV_df$Test_MSE = test_d_vec
knitr::kable(LOOCV_df[,c(1,k+2,k+3)],
format = "markdown",
caption = "Total MSE of LOOCV at different degrees on validation data.") # display table
# print best d value
print(paste("The best LOOCV degree is: ",
as.character(LOOCV_df[which.min(LOOCV_df$Total_validation_MSE),]$Degree)))
# estimate test data MSE
train_d_vec = c()
test_d_vec = c()
for(d in d_vec){
if(d==0){
# train a polynomial model
PR = lm(y ~ 1, data=train.df)
}else{
# train a polynomial model
PR = lm(y ~ poly(x, d, raw = TRUE), data=train.df)
}
# get predicted values to calculate MSE
pred_val = predict(PR, test.df, type="response")
pred_true_val_df = data.frame(pred = pred_val, actual = test.df$y)
#calculate MSE
mse = mean((pred_true_val_df$actual - pred_true_val_df$pred)^2)
test_d_vec = c(test_d_vec, mse)
# get predicted values to calculate MSE
pred_val = predict(PR, train.df, type="response")
pred_true_val_df = data.frame(pred = pred_val, actual = train.df$y)
#calculate MSE
mse = mean((pred_true_val_df$actual - pred_true_val_df$pred)^2)
train_d_vec = c(train_d_vec, mse)
}
# visualize LOOCV and K-fold CV
# calculate max and min limits of data KFOLD
# kfold_max_vec = apply(KFOLD_df[, 2:(ncol(KFOLD_df)-1)], 1, max)
# kfold_min_vec = apply(KFOLD_df[, 2:(ncol(KFOLD_df)-1)], 1, min)
kfold_mean_vec = apply(KFOLD_df[, 2:(ncol(KFOLD_df)-1)], 1, mean)
# calculate max and min limits of data for LOOCV
# loocv_max_vec = apply(LOOCV_df[, 2:(ncol(LOOCV_df)-1)], 1, max)
# loocv_min_vec = apply(LOOCV_df[, 2:(ncol(LOOCV_df)-1)], 1, min)
loocv_mean_vec = apply(LOOCV_df[, 2:(ncol(LOOCV_df)-2)], 1, mean)
{plot(x=KFOLD_df$Degree,
y=kfold_mean_vec,
ylab="Mean Squared Error",
main="Mean MSE from CV",
xlab="Degree of Polynomial",
type='b',
col='red',
pch = 16,
lwd=3,
ylim=c(3,4.5)
)
lines(x=LOOCV_df$Degree,
y=loocv_mean_vec,
type='b',
col='blue',
pch = 16,
lwd=3)
lines(x=LOOCV_df$Degree,
y=test_d_vec,
type='b',
col='black',
pch = 16,
lwd=3)
lines(x=LOOCV_df$Degree,
y=train_d_vec,
type='b',
col='black',
lty=3,
pch = 16,
lwd=3)
abline(v=KFOLD_df[which.min(KFOLD_df$Total_MSE),]$Degree,
col='red',
pch = 16,
lty=3,
lwd=3)
abline(v=LOOCV_df[which.min(LOOCV_df$Total_validation_MSE),]$Degree,
col='blue',
pch = 16,
lty=2,
lwd=3)
legend("topright",
inset = 0.01,
legend = c("Training LOOCV MSE",
"Training K-fold CV MSE",
"LOOCV best d",
"K-fold CV best d",
"Test data MSE (No CV)",
"Train data MSE (No CV)"),
lty = c(1,1,2,3,1,3),
col = c("blue", "red","blue", "red", "black", "black"),
lwd = 2)}
# parameters
set.seed(100)
d_vec = seq(0,4)
# generate data
train.df = genData(n=400,seed=100)
test.df = genData(400)
# create k-fold indexes
k=5
inds.part = myCVids(n=nrow(train.df),K=k)
# create a data frame to save results into
M = matrix(0, nrow = (length(d_vec)), ncol = k+1)
KFOLD_df = data.frame(M)
KFOLD_df[,1] = d_vec # add degrees to results table
colnames(KFOLD_df) = c("Degree", seq(k))
# loop over k-folds
for( k in seq(k)){
isk = (inds.part == k) # k varies from 1 to K
valid.k = which(isk) # test data index
train.k = which(!isk)
# split data
train_sub_df = train.df[train.k,]
valid_df = train.df[valid.k,]
d_mse_vec = c()
for(d in d_vec){
if(d==0){
# train a polynomial model
PR = lm(y ~ 1, data=train_sub_df)
}else{
# train a polynomial model
PR = lm(y ~ poly(x, d, raw = TRUE), data=train_sub_df)
}
# get predicted values to calculate MSE
pred_val = predict(PR, valid_df, type="response")
pred_true_val_df = data.frame(pred = pred_val, actual = valid_df$y)
#calculate MSE
mse = mean((pred_true_val_df$actual - pred_true_val_df$pred)^2)
d_mse_vec = c(d_mse_vec, mse)
}
KFOLD_df[,k+1] = d_mse_vec
}
# tally of MSE
KFOLD_df$Total_MSE = rowSums(KFOLD_df[2:ncol(KFOLD_df)])
knitr::kable(KFOLD_df,
format = "markdown",
caption = "MSE by 5 folds at different degrees on validation data.") # display table
# print best d value
print(paste("The best K-fold degree is: ",
as.character(KFOLD_df[which.min(KFOLD_df$Total_MSE),]$Degree)))
# create k-fold indexes
k=nrow(train.df)
inds.part = myCVids(n=nrow(train.df),K=k)
# create a data frame to save results into
M = matrix(0, nrow = (length(d_vec)), ncol = k+1)
LOOCV_df = data.frame(M)
LOOCV_df[,1] = d_vec # add degrees to results table
colnames(LOOCV_df) = c("Degree", seq(k))
# loop over k-folds
for( k in seq(k)){
isk = (inds.part == k) # k varies from 1 to K
valid.k = which(isk) # test data index
train.k = which(!isk)
# split data
train_sub_df = train.df[train.k,]
valid_df = train.df[valid.k,]
d_mse_vec = c()
for(d in d_vec){
if(d==0){
# train a polynomial model
PR = lm(y ~ 1, data=train_sub_df)
}else{
# train a polynomial model
PR = lm(y ~ poly(x, d, raw = TRUE), data=train_sub_df)
}
# get predicted values to calculate MSE
pred_val = predict(PR, valid_df, type="response")
pred_true_val_df = data.frame(pred = pred_val, actual = valid_df$y)
#calculate MSE
mse = mean((pred_true_val_df$actual - pred_true_val_df$pred)^2)
d_mse_vec = c(d_mse_vec, mse)
}
LOOCV_df[,k+1] = d_mse_vec
}
# estimate test data MSE
test_d_vec = c()
for(d in d_vec){
if(d==0){
# train a polynomial model
PR = lm(y ~ 1, data=train.df)
}else{
# train a polynomial model
PR = lm(y ~ poly(x, d, raw = TRUE), data=train.df)
}
# get predicted values to calculate MSE
pred_val = predict(PR, test.df, type="response")
pred_true_val_df = data.frame(pred = pred_val, actual = test.df$y)
#calculate MSE
mse = mean((pred_true_val_df$actual - pred_true_val_df$pred)^2)
test_d_vec = c(test_d_vec, mse)
}
# tally of MSE
LOOCV_df$Total_validation_MSE = rowSums(LOOCV_df[2:ncol(LOOCV_df)])
LOOCV_df$Test_MSE = test_d_vec
knitr::kable(LOOCV_df[,c(1,k+2,k+3)],
format = "markdown",
caption = "Total MSE of LOOCV at different degrees on validation data.") # display table
# print best d value
print(paste("The best LOOCV degree is: ",
as.character(LOOCV_df[which.min(LOOCV_df$Total_validation_MSE),]$Degree)))
# estimate test data MSE
train_d_vec = c()
test_d_vec = c()
for(d in d_vec){
if(d==0){
# train a polynomial model
PR = lm(y ~ 1, data=train.df)
}else{
# train a polynomial model
PR = lm(y ~ poly(x, d, raw = TRUE), data=train.df)
}
# get predicted values to calculate MSE
pred_val = predict(PR, test.df, type="response")
pred_true_val_df = data.frame(pred = pred_val, actual = test.df$y)
#calculate MSE
mse = mean((pred_true_val_df$actual - pred_true_val_df$pred)^2)
test_d_vec = c(test_d_vec, mse)
# get predicted values to calculate MSE
pred_val = predict(PR, train.df, type="response")
pred_true_val_df = data.frame(pred = pred_val, actual = train.df$y)
#calculate MSE
mse = mean((pred_true_val_df$actual - pred_true_val_df$pred)^2)
train_d_vec = c(train_d_vec, mse)
}
# visualize LOOCV and K-fold CV
# calculate max and min limits of data KFOLD
# kfold_max_vec = apply(KFOLD_df[, 2:(ncol(KFOLD_df)-1)], 1, max)
# kfold_min_vec = apply(KFOLD_df[, 2:(ncol(KFOLD_df)-1)], 1, min)
kfold_mean_vec = apply(KFOLD_df[, 2:(ncol(KFOLD_df)-1)], 1, mean)
# calculate max and min limits of data for LOOCV
# loocv_max_vec = apply(LOOCV_df[, 2:(ncol(LOOCV_df)-1)], 1, max)
# loocv_min_vec = apply(LOOCV_df[, 2:(ncol(LOOCV_df)-1)], 1, min)
loocv_mean_vec = apply(LOOCV_df[, 2:(ncol(LOOCV_df)-2)], 1, mean)
{plot(x=KFOLD_df$Degree,
y=kfold_mean_vec,
ylab="Mean Squared Error",
main="Mean MSE from CV",
xlab="Degree of Polynomial",
type='b',
col='red',
pch = 16,
lwd=3,
ylim=c(3.5,4.5)
)
lines(x=LOOCV_df$Degree,
y=loocv_mean_vec,
type='b',
col='blue',
pch = 16,
lwd=3)
lines(x=LOOCV_df$Degree,
y=test_d_vec,
type='b',
col='black',
pch = 16,
lwd=3)
lines(x=LOOCV_df$Degree,
y=train_d_vec,
type='b',
col='black',
lty=3,
pch = 16,
lwd=3)
abline(v=KFOLD_df[which.min(KFOLD_df$Total_MSE),]$Degree,
col='red',
pch = 16,
lty=3,
lwd=3)
abline(v=LOOCV_df[which.min(LOOCV_df$Total_validation_MSE),]$Degree,
col='blue',
pch = 16,
lty=2,
lwd=3)
legend("topright",
inset = 0.01,
legend = c("Training LOOCV MSE",
"Training K-fold CV MSE",
"LOOCV best d",
"K-fold CV best d",
"Test data MSE (No CV)",
"Train data MSE (No CV)"),
lty = c(1,1,2,3,1,3),
col = c("blue", "red","blue", "red", "black", "black"),
lwd = 2,
cex = 0.75)}
# assume values for x and cfp
# x = 0.25
cfp=1
n=100
x_vec=c()
A_vec=c()
C_vec=c()
R_vec=c()
FPR_vec=c()
TPR_vec=c()
G_vec=c()
for (x in seq(0.01,0.99,0.01)) {
A=c(0.5, 0.2)
C=c(cfp, 10*cfp)
R=c(x, sqrt(x))
Ai=0
for(q in A){
Ai = Ai+1
P=n*q
N=n*(1-q)
Ri=0
for(tpr in R){
Ri=Ri+1
# calculate TP, FP, TN, and FN with regards to x
TP = tpr*P
FN = P-TP
FP = x*N
TN = N-FP
FPR = x
TPR = tpr
Ci=0
for(cfn in C){
Ci=Ci+1
G = cfn*FN + cfp*FP
x_vec=c(x_vec,x)
A_vec=c(A_vec,Ai)
C_vec=c(C_vec,Ci)
R_vec=c(R_vec,Ri)
FPR_vec=c(FPR_vec,FPR)
TPR_vec=c(TPR_vec,TPR)
G_vec=c(G_vec,G)
# print(paste("(A:",as.character(Ai),")"))
# print(paste("(C:",as.character(Ci),")"))
# print(paste("(R:",as.character(Ri),")"))
# print(paste("FPR = ", FPR))
# print(paste("TPR = ", TPR))
# print(paste("G = ", G))
# print("----------------------------")
}
}
}
}
results_df = data.frame(x_vec,
A_vec,
C_vec,
R_vec,
FPR_vec,
TPR_vec,
G_vec)
results_df$design_id <- paste(results_df$A_vec,
results_df$C_vec,
results_df$R_vec)
# Objective function score visualization
{plot(x=results_df$x_vec,
y=results_df$G_vec,
col=factor(results_df$design_id),
ylab="G (misclassification cost)",
xlab="x (FPR)",
pch=20)
legend("topright",
inset = 0.01,
pch=c(19,19,19,19),
legend = c("A1:C2:R1",
"A1:C2:R2",
"A2:C2:R1",
"A2:C2:R2",
"A1:C1:R1",
"A1:C1:R2",
"A2:C1:R1",
"A2:C1:R2"),
col = c("green",
"blue",
"yellow",
"grey",
"black",
"red",
"cyan",
"purple"))}
knitr::kable(results_df, format = "markdown")
# Generate data
set.seed(0)
n_vec = c(25, 50, 100, 200, 400, 800)
m = 1000
df = data.frame(m=1:m)
table_df = data.frame(n=n_vec) # results table
mean_uniq_vec = c()
sd_uniq_vec = c()
for (n in n_vec){
I = seq(n)
samp_vec = c(sample(x=I, size=m ,replace=TRUE))
df[paste("n",n , sep="")] = samp_vec
mean_uniq_vec = c(mean_uniq_vec, mean(unique(samp_vec)))
sd_uniq_vec = c(sd_uniq_vec, sd(unique(samp_vec)))
}
# #visualize data
{par(mfrow=c(2,3))
for(i in names(df)[2:7]){
hist(df[[i]],
xlab = "Number",
main=i,
ylim=c(0,210),
breaks = as.numeric(substr(i,2,nchar(i)))/5)
}}
# bar plot of of unique values for different values of n
unique_df = t(data.frame(unique_sample_count = apply(df[, 2:(ncol(df))], 2, FUN=function(x){length(unique(x))}),
n=n_vec))
{par(mfrow=c(1,1))
barplot(
unique_df,
beside=TRUE
)}
# make table of results
table_df$Mean_Unique = myRound(mean_uniq_vec, acc=2)
table_df$SD_Unique = myRound(sd_uniq_vec, acc=2)
table_df = data.frame(t(table_df))
knitr::kable(table_df, format = "markdown")
