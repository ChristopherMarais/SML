---
title: "ABE6933 SML Take-Home Final Exam (100 pts + 10 pts bonus)"
author: "Christopher Marais"
output: pdf_document
fontsize: 11pt
geometry: margin=2cm
---
# Exam code & data
```{R}
myCVids <- function(n, K, seed=0) {
# balanced subsets generation (subset sizes differ by at most 1)
# n is the number of observations/rows in the training set
# K is the desired number of folds (e.g., 5 or 10)
set.seed(seed);
t = floor(n/K); r = n-t*K;
id0 = rep((1:K),times=t)
ids = sample(id0,t*K)
if (r > 0) {ids = c(ids, sample(K,r))}
ids
}

load('final.test.v1.Rdata')
```


# Problem 1
## 1.1
```{R}

```

## 1.2
```{R}

```

## 1.3
```{R}

```

## 1.4
```{R}

```

## 1.5
```{R}

```

## 1.6
```{R}

```

# Problem 2
```{R}

```

# Problem 3
```{R}
# initialize information
k = 5
d_max = 10

# Mode function
Mode <- function(x) {
  ox <- order(x)
  ux <- unique(ox)
  ux[which.max(tabulate(match(x, ux)))]
}

# Outer CV to estimate performance (seed=0)
n_i = nrow(prob3.df)
for(k_i in seq(k)){
  inds.part = myCVids(n=n_i, K=k, seed=0)
  isk = (inds.part == k_i)
  valid.i = which(isk)
  train.i = which(!isk)
  # split data into train and test sets
  data.valid.i = prob3.df[valid.i,]
  rownames(data.valid.i) <- NULL
  data.train.i = prob3.df[train.i,]
  rownames(data.train.i) <- NULL
  
  # Estimate performance 
  #########
  
  # Inner CV to estimate parameters (seed=1000)
  n_j = nrow(data.train.i)
  d_opt_vec = c()
  mse_opt_vec = c()
  for(k_j in seq(k)){
    inds.part = myCVids(n=n_j, K=k, seed=1000)
    isk = (inds.part == k_j)
    valid.j = which(isk)
    train.j = which(!isk)
    # split data into train and test sets
    data.valid.j = data.train.i[valid.j,]
    data.train.j = data.train.i[train.j,]

    # test different parameters (d)
    lm_results <- lapply(1:d_max, function(d) lm(y ~ poly(x, d), data = data.train.j))
    mse_vec = c()
    for(d in seq(d_max)){
      lm.fit = lm_results[[d]]
      mse = mean((data.valid.j$y - predict(lm.fit , data.valid.j))^2)
      mse_vec = c(mse_vec, mse)
    }
    d_opt = which.min(mse_vec)
    mse_opt = min(mse_vec)
    d_opt_vec = c(d_opt_vec, d_opt)
    mse_opt_vec = c(mse_opt_vec, mse_opt)
    
    d_mse_opt_df = data.frame(d_opt_vec, mse_opt_vec)
  }
  
  # select the mode of parameter d for all inner folds
  # if multiple modes, select the smallest value for d
  print(d_mse_opt_df)
  print(Mode(d_mse_opt_df$d_opt_vec))
}






```

```{R}
lm_results <- lapply(1:d_max, function(d) lm(y ~ poly(x, d), data = data.train.j))
mse_vec = c()
for(d in seq(d_max)){
  lm.fit = lm_results[[d]]
  mse = mean((data.valid.j$y - predict(lm.fit , data.valid.j))^2)
  mse_vec = c(mse_vec, mse)
}

d_opt = which.min(mse_vec)
```

# Problem 4
## 4.a
```{R}


```

## 4.b
```{R}

```

# Problem 5
```{R}

```

# Problem 6
```{R}

```
