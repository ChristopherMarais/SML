---
title: "ABE6933 SML Take-Home Final Exam (100 pts + 10 pts bonus)"
author: "Christopher Marais"
output: pdf_document
fontsize: 11pt
geometry: margin=2cm
---
# Exam code, data, and libraries
```{R}
# functions
myCVids <- function(n, K, seed=0) {
# balanced subsets generation (subset sizes differ by at most 1)
# n is the number of observations/rows in the training set
# K is the desired number of folds (e.g., 5 or 10)
set.seed(seed);
t = floor(n/K); r = n-t*K;
id0 = rep((1:K),times=t)
ids = sample(id0,t*K)
if (r > 0) {ids = c(ids, sample(K,r))}
ids
}

# function to generate all subsets of the set (1,2,...,p)
myf <- function(p) {
  out = matrix(c(0,1),nrow=2);
  if (p > 1) {
    for (i in (1:(p-1))) {
      d = 2^i
      o1 = cbind(rep(0,d),out)
      o2 = cbind(rep(1,d),out)
      out = rbind(o1,o2)
    }
  }
  colnames(out) <- c(2^((p-1):0)); # powers for binary expansion
  # colnames(out) <- c()
  out
}

nbSubsets <- function(p,m) {
  M  = myf(p)
  rs = rowSums(M)
  ii = (rs == m)
  (M[ii,])
}

# function to convert binary representation to decimal representation 
bin2dec <- function(binM) {
  dd = dim(binM);  # nrows and ncols
  p = dd[2]-1      # max power; 
  d = rep(0,dd[1]) # initialize placeholder for the answer
  for (i in 1:(p+1)) {
    d = d + 2^(p+1-i)*binM[,i]
  }
  d
}

# data
load('final.test.v1.Rdata')

# libraries
library(ROCR)
```


## My functions
```{R}
# functions
# Mis-classification ratio calculation
MCR <- function(target, predicted, threshold=0.5){
  if(length(target)!=length(predicted)){
    print("ERROR: predictions and true values not of same shape")
  }else{
    pred_vals = as.integer((predicted > threshold))
    mcr = sum(pred_vals != target)/length(target)
    return(mcr)
  }
}
```

# Problem 1
## 1.1
```{R}

```

## 1.2
```{R}

```

## 1.3
```{R}

```

## 1.4
```{R}

```

## 1.5
```{R}

```

## 1.6
```{R}

```

# Problem 2
```{R}

```

# Problem 3
```{R}
# initialize information
k = 5
d_max = 10

# Mode function
Mode <- function(x) {
  ox <- order(x)
  ux <- unique(ox)
  ux[which.max(tabulate(match(x, ux)))]
}

# Outer CV to estimate performance (seed=0)
n_i = nrow(prob3.df)
for(k_i in seq(k)){
  inds.part = myCVids(n=n_i, K=k, seed=0)
  isk = (inds.part == k_i)
  valid.i = which(isk)
  train.i = which(!isk)
  # split data into train and test sets
  data.valid.i = prob3.df[valid.i,]
  rownames(data.valid.i) <- NULL
  data.train.i = prob3.df[train.i,]
  rownames(data.train.i) <- NULL
  
  # Inner CV to estimate parameters (seed=1000)
  n_j = nrow(data.train.i)
  d_opt_vec = c()
  mse_opt_vec = c()
  for(k_j in seq(k)){
    inds.part = myCVids(n=n_j, K=k, seed=1000)
    isk = (inds.part == k_j)
    valid.j = which(isk)
    train.j = which(!isk)
    # split data into train and test sets
    data.valid.j = data.train.i[valid.j,]
    data.train.j = data.train.i[train.j,]

    # test different parameters (d)
    lm_results <- lapply(1:d_max, function(d) lm(y ~ poly(x, d), data = data.train.j))
    mse_vec = c()
    for(d in seq(d_max)){
      lm.fit.j = lm_results[[d]]
      mse_j = mean((data.valid.j$y - predict(lm.fit.j , data.valid.j))^2)
      mse_vec = c(mse_vec, mse_j)
    }
    d_opt = which.min(mse_vec)
    mse_opt = min(mse_vec)
    d_opt_vec = c(d_opt_vec, d_opt)
    mse_opt_vec = c(mse_opt_vec, mse_opt)
    
    d_mse_opt_df = data.frame(d_opt_vec, mse_opt_vec)
  }
  
  # select the mode of parameter d for all inner folds
  # if multiple modes, select the smallest value for d
  mode_d = Mode(d_mse_opt_df$d_opt_vec)
  
  # use mode_d to retrain polynomial model on data in outer CV
  lm.fit.i = lm(y ~ poly(x, mode_d), data = data.train.i)
  mse_i = mean((data.valid.i$y - predict(lm.fit.i , data.valid.i))^2)
  
  # estiamte performance
  print(paste(mode_d, mse_i))
}

# should model be trained in outer and inner loop? yes
# potential drawbacks are computation time
# Report mse and d for outer loop
# report mse and d for inner loop
# group them together print dataframe and then final d and final mse for each outer loop
```
# Problem 4
## 4.a
```{R, warning=FALSE}
# initialize data
p = 4
k_max = 5
n = nrow(prob4.df)
binM = myf(p)
ids = bin2dec(binM)
ROC_df = data.frame(matrix(ncol = length(ids), nrow = n), Y=prob4.df$Y)
colnames(ROC_df) = c(ids, "Y")

# loop through models
feature_names = c("X1","X2","X3","X4")
features_vec = c()
mean_mcr_vec = c()
for(i in seq(1:length(ids))){
  
  # select subset of data
  gamma = binM[i,]
  alpha = ids[i]
  X = data.frame(Intercept=1, prob4.df[,-5][,gamma==1])
  Y = prob4.df$Y
  data_df = data.frame(Y, X)
  
  # get feature names of id
  if(sum(gamma)==0){
    features = "None"
  }else{
    features = feature_names[gamma==1]
  }
  features_vec = c(features_vec, paste(features,collapse=" "))

  # perform 5-fold CV
  inds.part = myCVids(n, 5, seed=0)
  # loop through folds
  mcr_vec = c()
  for(k in seq(1:k_max)){
    isk = (inds.part == k)
    valid.k = which(isk)
    train.k = which(!isk)

    # train logistic regression model
    glm.fit = glm(Y ~ 0 +.,
                 family=binomial,
                 data=as.data.frame(data_df[train.k,]))
    print(summary(glm.fit))
    
    # predict target on validation data  
    pred = predict(glm.fit , data_df[valid.k,])
    ROC_df[valid.k,i] = pred
    
    # calculate mis-classification error rate for default 0.5 threshold
    mcr = MCR(target=data_df[valid.k,]$Y, predicted=pred, threshold=0.5)
    mcr_vec = c(mcr_vec, mcr)
  }
  mean_mcr = mean(mcr_vec)
  mean_mcr_vec = c(mean_mcr_vec, mean_mcr)
}

# add data to a data frame
res_df = data.frame(ids,
features_vec,
mean_mcr_vec)
colnames(res_df) = c("ID", "covariates", "mean_mcr")
res_df = res_df[order(res_df$mean_mcr),]
rownames(res_df) = NULL
knitr::kable(res_df, format = "markdown")

print(res_df[1,])
```

## 4.b
```{R}
# set threshold resolution for ROC curve
threshold_vec = seq(0, 1, 0.1)
best_model = res_df[1,1]
k_max = 5

# data of best model
Y_pred = ROC_df[,best_model+1]
Y = ROC_df[,ncol(ROC_df)]

# looping hrough the folds seem to not be he way they want it.
# create ROC curve for the best model
inds.part = myCVids(n, 5, seed=0)
for(k in seq(1:k_max)){
  isk = (inds.part == k)
  valid.k = which(isk)
  
  pred <- prediction(Y_pred[valid.k], Y[valid.k])
  perf <- performance(pred,'tpr','fpr')
  plot(perf,
       lwd=2,
       main='ROC curves from 5-fold cross-validation')
}



# this way seems to be the correct one
pred <- prediction(Y_pred, Y)
perf <- performance(pred,'tpr','fpr')


plot(perf,
     lwd=2,
     main='ROC curves from 5-fold cross-validation')
```


# Problem 5
```{R}

```

# Problem 6
```{R}

```
